Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from kompas_theme
if(asfv$source_web[i] == "kompas_theme") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".read__time") %>%                  #read the codes, take all nodes
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".read__title") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asfv[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("p") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from republik
if(asfv$source_web[i] == "republik") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".date-item__headline") %>%                  #read the codes, take all nodes
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("h1") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asfv[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("p") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
write.csv2(asfv,"D:/015_africanswinefever_rf/003_sm_asf/data/asf_newsstep50.csv")
for (i in 1:nrow(asfv)) {
#for scrape web source from salam_papua
if(asfv$source_web[i] == "salam_papua") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("ul.post-info-dark li") %>%                  #read the codes, take all nodes
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("h2") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asfv[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("p") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from salam_papua
if(asfv$source_web[i] == "salam_papua") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("li") %>% .[2] %>%                  #read the codes, take all nodes
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("h2") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asfv[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("p") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from salam_papua
if(asfv$source_web[i] == "salam_papua") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("ul.post-info-dark li") %>% .[2] %>%                  #read the codes, take all nodes anf choose 2nd
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("title-semibold-dark size-c30") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from salam_papua
if(asfv$source_web[i] == "salam_papua") {
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("h2.title-semibold-dark size-c30") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asfv[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("p") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from salam_papua
if(asfv$source_web[i] == "salam_papua") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("ul.post-info-dark li") %>% .[2] %>%                  #read the codes, take all nodes anf choose 2nd
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("h2.title-semibold-dark size-c30") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asfv[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("p") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from salam_papua
if(asfv$source_web[i] == "salam_papua") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("ul.post-info-dark li") %>% .[2] %>%                  #read the codes, take all nodes anf choose 2nd
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("h2.title-semibold-dark.size-c30") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asfv[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("p") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from sindo_news
if(asfv$source_web[i] == "sindo_news") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".detail-date-artikel") %>%                  #read the codes, take all nodes anf choose 2nd
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("h1") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asfv[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("#detail-desc") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from tirto
if(asfv$source_web[i] == "tirto") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("div.byline div:nth-child(2)") %>%                  #read the codes, take all nodes anf choose 2nd
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".article-title") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asfv[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("p") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from kumparan
if(asfv$source_web[i] == "kumparan") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".txregular") %>%                  #read the codes, take all nodes anf choose 2nd
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asfv[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".txdisplay-semilarge") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asfv[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes(".txextra-large") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asfv)) {
#for scrape web source from kumparan
if(asfv$source_web[i] == "kumparan") {
#extract article publication
asfv [i,"news_publish"] <-
polite::bow(asfv[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("span[data-qa-id='publish-date']") %>%                  #read the codes, take all nodes anf choose 2nd
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
write.csv2(asfv,"D:/015_africanswinefever_rf/003_sm_asf/data/asf_newsstep54.csv")
#1 open file CSV
library(readr)
asf <- read.csv2("D:/015_africanswinefever_rf/003_sm_asf/data/asf_newsstep54.csv")
View(asf)     #see table of content
#2.1 install packages that used
install.packages("dplyr")
install.packages("polite")
install.packages("rvest")
install.packages("magrittr")
install.packages("stringr")
#2.2 activate packages that used
library(dplyr)
library(polite)
library(rvest)
library(magrittr)
library(stringr)
for (i in 1:nrow(asf)) {
#for scrape web source from analisadaily
if(asf$source_web[i] == "analisadaily") {
#extract article publication
asf [i,"news_publish"] <-
polite::bow(asf[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("i") %>%                  #read the codes, take all nodes
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asf[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("h2") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asf[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("p") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asf)) {
#for scrape web source from analisadaily
if(asf$source_web[i] == "analisadaily") {
#extract article publication
asf [i,"news_publish"] <-
polite::bow(asf[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("li[i='fa.fa-clock-o']") %>%                  #read the codes, take all nodes
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asf)) {
#for scrape web source from analisadaily
if(asf$source_web[i] == "analisadaily") {
#extract article publication
asf [i,"news_publish"] <-
polite::bow(asf[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node("ul.post-meta li:first-child") %>%                  #read the codes, take all nodes
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asf)) {
#for scrape web source from bali post
if(asf$source_web[i] == "bali_post") {
#extract article publication
asf [i,"news_publish"] <-
polite::bow(asf[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".td-module-date") %>%                  #read the codes, take all nodes
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asf[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".entry-title") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asf[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes(c("h2","p")) %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asf)) {
#for scrape web source from bali post
if(asf$source_web[i] == "bali_post") {
#extract article publication
asf [i,"news_publish"] <-
polite::bow(asf[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".td-module-date") %>%                  #read the codes, take all nodes
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asf[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".entry-title") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asf[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes(c("h2","p")) %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
for (i in 1:nrow(asf)) {
#for scrape web source from bali post
if(asf$source_web[i] == "bali_post") {
#extract article publication
asf [i,"news_publish"] <-
polite::bow(asf[i,"url"]) %>%                   #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".td-module-date") %>%                  #read the codes, take all nodes
rvest::html_text() %>%                          #change in to text format
stringr::str_trim()                             #remove extra spaces
#extract  article title
asf[i,"news_title"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_node(".entry-title") %>%                      #read the title codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(.,"[\r\n\t\"]", "") %>% #remomve line breaks and all symbols
stringr::str_trim()                             #remove extra spaces
#extract article content
asf[i,"news_content"] <-
polite::bow(asfv[i,"url"]) %>%            #introduce yourself to the host
polite::scrape(.) %>%                           #scrape the content of authorized page
rvest::html_nodes("h2,p") %>%                   #read the content codes
rvest::html_text() %>%                          #change in to text format
stringr::str_replace_all(., "[\r\n\t\"]","") %>% #remomve line breaks and all symbols
stringr::str_trim() %>%                         #remove extra spaces
paste(collapse="")                              #combine all sentences
#add sleep time (10 seconds)
Sys.sleep(10)
} else(next)
}
